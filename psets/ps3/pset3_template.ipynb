{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center> Problem Set 3 <center>\n",
    "\n",
    "<center> 3.C01/3.C51, 7.C01/7.C51, 10.C01/10.C51, 20.C01/20.C51 <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Name:</b>\n",
    "\n",
    "<b>Kerberos id:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "matplotlib.rc('lines', linewidth=3, color='g')\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams[\"xtick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 2\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 2\n",
    "matplotlib.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Problem 1: Predicting DNA Binding Sites</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data \n",
    "! wget https://raw.githubusercontent.com/vikram-sundar/ML4MolEng_Spring2022/master/psets/ps3/data/train_dna.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv(\"./train_dna.csv\")\n",
    "\n",
    "X = train_pd.seq.values\n",
    "y = train_pd.bind.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 (15 points) Build Datasets and DataLoaders in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode DNA sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeqEnc(sequences):\n",
    "    # Write your one-hot encoding code here\n",
    "    \n",
    "    # sequences - an array of DNA sequences as strings\n",
    "    \n",
    "X = SeqEnc(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your dataset class that takes in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset \n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X)  # store X as a pytorch Tensor\n",
    "        self.y = torch.Tensor(y)  # store y as a pytorch Tensor\n",
    "        self.len=len(self.X)      # number of samples in the data \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # your implementation here: \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your Datasets and DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset \n",
    "X_train = # fill in code here\n",
    "y_train = # fill in code here\n",
    "X_val = # fill in code here\n",
    "y_val = # fill in code here\n",
    "X_test = # fill in code here\n",
    "y_test = # fill in code here\n",
    "\n",
    "#Build Dataset \n",
    "train_data = # fill in code here\n",
    "val_data = # fill in code here\n",
    "test_data = # fill in code here\n",
    "\n",
    "# Build DataLoader \n",
    "batch_size = 256\n",
    "train_loader = # fill in code here\n",
    "val_loader = # fill in code here\n",
    "test_loader = # fill in code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the benefit of batching your data into mini-batches versus using the entire dataset to optimize the model all at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 (20 points) Build an LSTM-based binding classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example will help familiarize you with the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a LSTM module \n",
    "lstm_model = nn.LSTM(input_size=4, hidden_size=16, batch_first=True).to(\"cuda:0\") # \"cuda:0\" is the device id\n",
    "\n",
    "# Send your batch to a GPU \n",
    "X_batch, y_batch = next(iter(train_loader))\n",
    "X_batch = X_batch.to(\"cuda:0\")\n",
    "y_batch = y_batch.to(\"cuda:0\")\n",
    "\n",
    "# Propagate your batch into your model \n",
    "lstm_out, (ht, ct) = lstm_model(X_batch) \n",
    "print(lstm_out.shape, ht.shape, ct.shape)\n",
    "\n",
    "# You can play with hyperparameters to see how your output changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build your LSTM-based classifier as a nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMseq(torch.nn.Module) :\n",
    "    def __init__(self, input_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define a LSTM module\n",
    "        \n",
    "        # Define a MLP regressor \n",
    "        \n",
    "        # Define a sigmoid transform\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Apply LSTM \n",
    "        \n",
    "        # Pass output into a MLP \n",
    "        \n",
    "        # Transform output into probabilites \n",
    "        \n",
    "        # Return probabilities \n",
    "        \n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your output on a batch \n",
    "clf = LSTMseq(input_dim=4, hidden_dim=16).to('cuda:0')\n",
    "print(clf(X_batch).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 (25 points) Implement functions for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your optimizer and scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "model = LSTMseq(4, 16).to(device)\n",
    "\n",
    "optimizer = # complete optimizer here\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True, factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and validation loops and evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, device):\n",
    "    \n",
    "    '''\n",
    "    A function to train on the entire dataset for one epoch.\n",
    "    \n",
    "    Args: \n",
    "        model (torch.nn.Module): Your sequence classifier \n",
    "        dataloader (torch.utils.data.Dataloader): DataLoader object for the train data\n",
    "        optimizer (torch.optim.Optimizer): Optimizer object to interface gradient calculation and optimization \n",
    "        device (str): Your device\n",
    "        \n",
    "    Returns: \n",
    "        float: loss averaged over all the batches \n",
    "    \n",
    "    '''\n",
    "\n",
    "    batch_loss = []\n",
    "    model.train() # Set model to training mode \n",
    "    \n",
    "    for batch in dataloader:    \n",
    "        seq, label = batch\n",
    "        seq = seq.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        # train your model on each batch here \n",
    "\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    \n",
    "    '''\n",
    "    A function to validate on the validation dataset for one epoch.\n",
    "    \n",
    "    Args: \n",
    "        model (torch.nn.Module): Your sequence classifier \n",
    "        dataloader (torch.utils.data.Dataloader): DataLoader object for the validation data\n",
    "        device (str): Your device\n",
    "        \n",
    "    Returns: \n",
    "        float: loss averaged over all the batches \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    val_loss = []\n",
    "    model.eval() # Set model to evaluation mode \n",
    "    with torch.no_grad():    \n",
    "        for batch in dataloader:\n",
    "            seq, label = batch\n",
    "            seq = seq.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # validate your model on each batch here \n",
    "            \n",
    "    return 0.0    \n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "\n",
    "    '''\n",
    "    A function to return the classification probabilities and true labels (for evaluation). \n",
    "    \n",
    "    Args: \n",
    "        model (torch.nn.Module): your sequence classifier \n",
    "        dataloader (torch.utils.data.Dataloader): DataLoader object for the train data\n",
    "        device (str): Your device\n",
    "        \n",
    "    Returns: \n",
    "        (np.array, np.array): true labels, predicted probabilities\n",
    "    '''\n",
    "\n",
    "    pred_prob = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in dataloader:\n",
    "            epoch_loss = []\n",
    "            seq, label = batch\n",
    "\n",
    "            seq = seq.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # evaluate your model here\n",
    "            \n",
    "    return labels, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epoch\", \"train loss\", \"validation loss\")\n",
    "\n",
    "val_loss_curve = []\n",
    "train_loss_curve = []\n",
    "\n",
    "for epoch in range(500):\n",
    "    \n",
    "    # Compute train your model on training data\n",
    "    epoch_loss = train(model, train_loader, optimizer,  device=0)\n",
    "    \n",
    "    # Validate your on validation data \n",
    "    val_loss = validate(model, val_loader, device=0) \n",
    "    \n",
    "    # Record train and loss performance \n",
    "    train_loss_curve.append(epoch_loss)\n",
    "    val_loss_curve.append(val_loss)\n",
    "    \n",
    "    # The learning rate scheduler records the validation loss \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(epoch, epoch_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot train and validation loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(val_loss_curve, label='Validation Loss')\n",
    "ax.plot(train_loss_curve, label='Training Loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend(loc='upper right')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the AUC on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to compute AUC on test data \n",
    "\n",
    "    \n",
    "print(\"AUC on the test dataset is {}.\".format(test_score) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Dimensionality Reduction for Molecular Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/vikram-sundar/ML4MolEng_Spring2022/master/psets/ps3/data/drug.csv\n",
    "! wget https://raw.githubusercontent.com/vikram-sundar/ML4MolEng_Spring2022/master/psets/ps3/data/morgan.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "df = pd.read_csv(\"drug.csv\")\n",
    "fp = np.loadtxt('morgan.csv', delimiter=',')\n",
    "\n",
    "assert fp.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (10 points) Principal Component Analysis on Molecular Fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA to reduce data into vectors of 100 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# skeleton code for plotting\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter([0], [0], s=3, label='inactive') \n",
    "ax.scatter([0], [0], color='red', s= 3, label='active')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the explained variance ratio of the 100 principal components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"The first 100 components explains {} of the total variance\".format(1.0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What patterns do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 (10 points) t-SNE analysis on Molecular Fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform t-SNE on the obtained principal components, with perplexity value of 2, 30, and 500. Plot the results and label your plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What differences do you see between the 3 t-SNE plots? What patterns do you observe in the perplexity = 30 plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 (15 points) Are the low dimensional embeddings meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 10 folds. For each fold, train on the other 9 folds and validate on the last fold. Record your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify your predictions into True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 2D t-SNE embeddings (perplexity = 30) colored by the four classification classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What pattern do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
