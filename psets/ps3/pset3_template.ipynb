{"cells":[{"cell_type":"markdown","metadata":{"id":"xlOtIehkfv94"},"source":["#  <center> Problem Set 3 <center>\n","<center> 3.C01/3.C51, 7.C01/7.C51, 10.C01/10.C51, 20.C01/20.C51<center>"]},{"cell_type":"markdown","metadata":{"id":"k-ST-K4gfv98"},"source":["<b>Name:</b>\n","\n","<b>Kerberos id:</b>"]},{"cell_type":"markdown","metadata":{"id":"KRjyJW47RVfB"},"source":["### Download required data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":989,"status":"ok","timestamp":1709820942330,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"QgfwXqRsRJKN","outputId":"ebc2c230-1547-4ce8-8e16-051c0a7a0667"},"outputs":[],"source":["! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps3/data/solubility.csv\n","! wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps3/data/dna_binding.csv\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22186,"status":"ok","timestamp":1709820969014,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"pk5qQd7fsEcw","outputId":"cb76b2a0-d830-43fe-b679-ab4b6bae87eb"},"outputs":[],"source":["#install RDKit\n","!pip install rdkit\n","\n","import numpy as np\n","from rdkit import Chem, DataStructs\n","from rdkit.Chem import Descriptors,Crippen\n","from rdkit.Chem import Draw\n","from rdkit.Chem.Draw import IPythonConsole\n","import itertools\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score, r2_score\n","from sklearn.utils import shuffle\n","\n","matplotlib.rcParams.update({'font.size': 15})\n","matplotlib.rc('lines', linewidth=3, color='g')\n","matplotlib.rcParams['axes.linewidth'] = 2.0\n","matplotlib.rcParams['axes.linewidth'] = 2.0\n","matplotlib.rcParams[\"xtick.major.size\"] = 6\n","matplotlib.rcParams[\"ytick.major.size\"] = 6\n","matplotlib.rcParams[\"ytick.major.width\"] = 2\n","matplotlib.rcParams[\"xtick.major.width\"] = 2\n","matplotlib.rcParams['text.usetex'] = False"]},{"cell_type":"markdown","metadata":{"id":"eVAkamN4fv99"},"source":["## <center>Problem 1: Predicting DNA Binding Sites</center>"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1709824954309,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"fiP9YQbAfv-B"},"outputs":[],"source":["df = pd.read_csv(\"./dna_binding.csv\")\n","\n","sequences = df.seq.values\n","y = df.bind.values"]},{"cell_type":"markdown","metadata":{"id":"PGGr1meefv-F"},"source":["### 1.1 (10 points) Build Datasets and DataLoaders in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"QZQbraP0fv-G"},"source":["One-hot encode DNA sequence data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1459,"status":"ok","timestamp":1709824957744,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"9xeLtJMYfv-G","outputId":"0a85bfd3-382b-4bad-c3f9-0d6c94d271d7"},"outputs":[],"source":["def SeqEnc(sequences):\n","    '''\n","    A function to one-hot encode DNA sequences\n","\n","    Args:\n","        sequences (list): list of DNA sequences\n","\n","    Returns:\n","        np.array: array with shape (N,C,4) where N is the number of sequences\n","        and C is the sequence length\n","    '''\n","    ################ Code #################\n","\n","\n","    ################ Code #################\n","\n","X = SeqEnc(sequences)\n","print(\"Shape of X is {}.\".format(X.shape))"]},{"cell_type":"markdown","metadata":{"id":"_yFZOk37fv-H"},"source":["Implement your dataset class that takes in your data."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709824957884,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"3fAAi_9mfv-H"},"outputs":[],"source":["# Generate dataset\n","class SequenceDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.Tensor(np.array(X))  # store X as a pytorch Tensor\n","        self.y = torch.Tensor(np.array(y))  # store y as a pytorch Tensor\n","        self.len=len(self.X)                # number of samples in the data\n","\n","    def __getitem__(self, index):\n","        # your implementation here:\n","        \n","    def __len__(self):\n","        return self.len\n"]},{"cell_type":"markdown","metadata":{"id":"cCw7zzVifv-I"},"source":["Define your Datasets and DataLoaders."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":155,"status":"ok","timestamp":1709824960415,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"nDcFKq7-fv-J"},"outputs":[],"source":["# Define dataset\n","X_train = None # fill in code here\n","y_train = None # fill in code here\n","X_val = None # fill in code here\n","y_val = None # fill in code here\n","X_test = None # fill in code here\n","y_test = None # fill in code here\n","\n","#Build Dataset\n","train_data = None # fill in code here\n","val_data = None # fill in code here\n","test_data = None # fill in code here\n","\n","# Build DataLoader\n","batch_size = 256\n","train_loader = None # fill in code here\n","val_loader = None # fill in code here\n","test_loader = None # fill in code here"]},{"cell_type":"markdown","metadata":{"id":"h2Kqx23Jfv-L"},"source":["What is the benefit of batching your data into mini-batches versus using the entire dataset to optimize the model all at once?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWmmiXFZfv-M"},"outputs":[],"source":["################ Answer #################\n","\n","################ Answer #################"]},{"cell_type":"markdown","metadata":{"id":"yy0Uy4nffv-M"},"source":["### 1.2 (20 points) Build an LSTM-based binding classifier"]},{"cell_type":"markdown","metadata":{"id":"mQUZo1FKfv-M"},"source":["The following example will help familiarize you with the LSTM."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1709824962744,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"vhmkBZerfv-N","outputId":"8de5f6ce-b33c-4488-b297-23a5ef5f7fd7"},"outputs":[],"source":["# Define a LSTM module\n","lstm_model = nn.LSTM(input_size=4, hidden_size=16, num_layers=1, batch_first=True, bidirectional=True).to(\"cpu\") # \"cpu\" is the device id\n","\n","# Send your batch to a GPU\n","X_batch, y_batch = next(iter(train_loader))\n","X_batch = X_batch.to(\"cpu\")\n","y_batch = y_batch.to(\"cpu\")\n","\n","# Propagate your batch into your model\n","lstm_out, (ht, ct) = lstm_model(X_batch)\n","print(lstm_out.shape, ht.shape, ct.shape)\n","\n","# You can play with hyperparameters to see how your output change"]},{"cell_type":"markdown","metadata":{"id":"DrKDF4AJfv-O"},"source":["Now build your LSTM-based classifier as a nn.Module."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":166,"status":"ok","timestamp":1709821904843,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"rVLRqmtgfv-O"},"outputs":[],"source":["class LSTMseq(torch.nn.Module) :\n","    def __init__(self, input_dim, hidden_dim) :\n","        super().__init__()\n","\n","        # Define a LSTM module\n","\n","        # Define a MLP regressor\n","\n","        # Define a sigmoid transform\n","\n","    def forward(self, x):\n","\n","        # Apply LSTM\n","\n","        # Pass output into a MLP\n","\n","        # Transform output into probabilites\n","\n","        # Return probabilities\n","        proba = None\n","\n","        return proba"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1709821972661,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"jN6oVCyyfv-O","outputId":"a06ec585-6f4b-4f3b-8568-52b1ad571f49"},"outputs":[],"source":["# Test your ouput on a batch\n","clf = LSTMseq(input_dim=4, hidden_dim=16).to('cpu')\n","print(clf(X_batch).shape)"]},{"cell_type":"markdown","metadata":{"id":"PXqpwHtMfv-P"},"source":["### 1.3 (20 points) Implement functions for training and testing"]},{"cell_type":"markdown","metadata":{"id":"UeqvPdTvn-3Y"},"source":["The training and validation loops and evaluation function."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1709822077569,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"uwcE6igLfv-P"},"outputs":[],"source":["def train(model, dataloader, optimizer, device):\n","\n","    '''\n","    A function to train on the entire dataset for one epoch.\n","\n","    Args:\n","        model (torch.nn.Module): Your sequence classifier\n","        dataloader (torch.utils.data.Dataloader): DataLoader object for the train data\n","        optimizer (torch.optim.Optimizer): Optimizer object to interface gradient calculation and optimization\n","        device (str): Your device\n","\n","    Returns:\n","        float: loss averaged over all the batches\n","\n","    '''\n","\n","    batch_loss = []\n","    model.train() # Set model to training mode\n","\n","    for batch in dataloader:\n","        seq, label = batch\n","        seq = seq.to(device)\n","        label = label.to(device)\n","\n","        # train your model on each batch here\n","\n","    return 0.0\n","\n","\n","def validate(model, dataloader, device):\n","\n","    '''\n","    A function to validate on the validation dataset for one epoch.\n","\n","    Args:\n","        model (torch.nn.Module): Your sequence classifier\n","        dataloader (torch.utils.data.Dataloader): DataLoader object for the validation data\n","        device (str): Your device\n","\n","    Returns:\n","        float: loss averaged over all the batches\n","\n","    '''\n","\n","    val_loss = []\n","    model.eval() # Set model to evaluation mode\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            seq, label = batch\n","            seq = seq.to(device)\n","            label = label.to(device)\n","\n","            # validate your model on each batch here\n","\n","    return 0.0\n","\n","def evaluate(model, dataloader, device):\n","\n","    '''\n","    A function to return the classification probabilities and true labels (for evaluation).\n","\n","    Args:\n","        model (torch.nn.Module): your sequence classifier\n","        dataloader (torch.utils.data.Dataloader): DataLoader object for the train data\n","        device (str): Your device\n","\n","    Returns:\n","        (np.array, np.array): true labels, predicted probabilities\n","    '''\n","\n","    pred_prob = []\n","    labels = []\n","    with torch.no_grad():\n","        model.eval()\n","        for batch in dataloader:\n","            epoch_loss = []\n","            seq, label = batch\n","\n","            seq = seq.to(device)\n","            label = label.to(device)\n","\n","            # evaluate your model here\n","\n","    return labels, pred_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29975,"status":"ok","timestamp":1709825881373,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"fE0-zkOafv-Q","outputId":"d378e520-02aa-4bf1-cbd0-72e51873435d"},"outputs":[],"source":["device = 'cuda:0'\n","model = LSTMseq(4, 16).to(device)\n","\n","optimizer = torch.optim.Adam(list(model.parameters()), lr=0.01)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True, factor=0.5)\n","\n","val_loss_curve = []\n","train_loss_curve = []\n","\n","# Use tqdm for progress bar\n","tqdm_progress =  tqdm(range(500), desc=\"Progress\")\n","\n","for epoch in tqdm_progress:\n","    # Compute train your model on training data\n","    epoch_loss = train(model, train_loader, optimizer,  device=device)\n","\n","    # Validate your on validation data\n","    val_loss = validate(model, val_loader, device=device)\n","\n","    # Record train and loss performance\n","    train_loss_curve.append(epoch_loss)\n","    val_loss_curve.append(val_loss)\n","\n","    # The learning rate scheduler record the validation loss\n","    scheduler.step(val_loss)\n","    tqdm_progress.set_postfix(train_loss=f'{epoch_loss:.3f}', val_loss=f'{val_loss:.3f}', refresh=True)"]},{"cell_type":"markdown","metadata":{"id":"Mc-un62Ufv-R"},"source":["Plot train and validation loss functions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"WYUSvgUifv-R","outputId":"3677b858-b3b5-46d6-e939-422334921aad"},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(6, 4))\n","ax.plot(val_loss_curve, label='Validation Loss')\n","ax.plot(train_loss_curve, label='Training Loss')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Loss')\n","ax.legend(loc='upper right')\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"gTLRxj4gfv-R"},"source":["Report the AUC on test data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6t6xEXZ-fv-S","outputId":"b33b9ca0-1691-47d0-9bc4-57356f0d75db"},"outputs":[],"source":["################ Code #################\n","\n","################ Code #################\n","\n","print(\"AUC on the test dataset is {}.\".format(test_score) )"]},{"cell_type":"markdown","metadata":{"id":"lzJZLo1_fv-T"},"source":["##Part 2: Predicting molecular properties with Graph Convolutional Nets"]},{"cell_type":"markdown","metadata":{"id":"Vh92cyI0RyKr"},"source":["### 2.1 (5 points) Try out RDKit"]},{"cell_type":"markdown","metadata":{"id":"eiBPuyAhR2RY"},"source":["RDKit example"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1709774525103,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"5S_sy74dRrr9","outputId":"be1472a3-9150-435a-9516-fc0d8ea07020"},"outputs":[],"source":["dopamine_mol = Chem.MolFromSmiles(\"C1=CC(=C(C=C1CCN)O)O\") # Dopamine\n","caffeine_mol = Chem.MolFromSmiles(\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\") # Caffeine\n","# Arrange molecules in a grid image\n","Draw.MolsToGridImage([dopamine_mol, caffeine_mol])"]},{"cell_type":"markdown","metadata":{"id":"AxRqdl-vR5Va"},"source":["Use RDKit to visualize 4 of your favorite molecules"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1709822863780,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"bG5itZvAR7Is","outputId":"19cff951-beaf-4823-c864-c2390e802d6b"},"outputs":[],"source":["################ Code #################\n"]},{"cell_type":"markdown","metadata":{"id":"vwfUlfMiSzjE"},"source":["### 2.2 (10 points) Construct Molecular Graph Datasets and DataLoaders"]},{"cell_type":"markdown","metadata":{"id":"_WP017b_S91O"},"source":["A SMILES to graph conversion function."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":130,"status":"ok","timestamp":1709824067329,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"y77BIe7RS8NK"},"outputs":[],"source":["def smiles2graph(smiles):\n","    '''\n","    Transform smiles into a list of atomic numbers and an edge array\n","\n","    Args:\n","        smiles (str): SMILES strings\n","\n","    Returns:\n","        z(np.array), A (np.array): list of atomic numbers, edge array\n","    '''\n","\n","    mol = Chem.MolFromSmiles( smiles ) # no hydrogen\n","    z = np.array( [atom.GetAtomicNum() for atom in mol.GetAtoms()] )\n","    A = np.stack(Chem.GetAdjacencyMatrix(mol)).nonzero()\n","\n","    return z, A"]},{"cell_type":"markdown","metadata":{"id":"K9b0fhb4TDXM"},"source":["Read in the DataFrame, shuffle its rows, and store its properties as lists."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5258,"status":"ok","timestamp":1709824074265,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"uCoU5QELTOF_"},"outputs":[],"source":["df = pd.read_csv(\"solubility.csv\")\n","df = shuffle(df).reset_index()\n","\n","AtomicNum_list = [] #list of torch.LongTensor\n","Edge_list = [] #list of torch.LongTensor\n","y_list = [] #list of torch.FloatTensor\n","Natom_list = [] #list of int\n","\n","################ Code #################\n"]},{"cell_type":"markdown","metadata":{"id":"djDpilZcUEQf"},"source":["A GraphDataset class for you to store graphs in PyTorch."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709824074265,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"iss6GvOTUGD-"},"outputs":[],"source":["class GraphDataset(torch.utils.data.Dataset):\n","    def __init__(self,\n","                 AtomicNum_list,\n","                 Edge_list,\n","                 Natom_list,\n","                 y_list):\n","\n","        '''\n","        GraphDataset object\n","\n","        Args:\n","            z_list (list of torch.LongTensor)\n","            a_list (list of torch.LongTensor)\n","            N_list (list of int)\n","            y_list (list of torch.FloatTensor)\n","\n","        '''\n","        self.AtomicNum_list = AtomicNum_list # atomic number\n","        self.Edge_list = Edge_list # edge list\n","        self.Natom_list = Natom_list # Number of atoms\n","        self.y_list = y_list # properties to predict\n","\n","    def __len__(self):\n","        return len(self.Natom_list)\n","\n","    def __getitem__(self, idx):\n","\n","        AtomicNum = torch.LongTensor(self.AtomicNum_list[idx])\n","        Edge = torch.LongTensor(self.Edge_list[idx])\n","        Natom = self.Natom_list[idx]\n","        y = torch.Tensor(self.y_list[idx])\n","\n","        return AtomicNum, Edge, Natom, y"]},{"cell_type":"markdown","metadata":{"id":"3uq9QcuRURJT"},"source":["Split your dataset into train, validation, and test and define the GraphDataset class for each."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1709824074265,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"brAFywvkUUwo"},"outputs":[],"source":["################ Code #################\n","\n","train_dataset = None # fill this in\n","val_dataset = None # fill this in\n","test_dataset = None # fill this in"]},{"cell_type":"markdown","metadata":{"id":"8GBkjSS1U4WO"},"source":["A graph collation function to batch multiple graphs into one batch."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":140,"status":"ok","timestamp":1709824076022,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"lJ_AKnBMU7GU"},"outputs":[],"source":["def collate_graphs(batch):\n","    '''Batch multiple graphs into one batched graph\n","\n","    Args:\n","\n","        batch (tuple): tuples of AtomicNum, Edge, Natom and y obtained from GraphDataset.__getitem__()\n","\n","    Return\n","        (tuple): Batched AtomicNum, Edge, Natom, y\n","\n","    '''\n","\n","    AtomicNum_batch = []\n","    Edge_batch = []\n","    Natom_batch = []\n","    y_batch = []\n","\n","    cumulative_atoms = np.cumsum([0] + [b[2] for b in batch])[:-1]\n","\n","    for i in range(len(batch)):\n","        z, a, N, y = batch[i]\n","        index_shift = cumulative_atoms[i]\n","        a = a + index_shift\n","        AtomicNum_batch.append(z)\n","        Edge_batch.append(a)\n","        Natom_batch.append(N)\n","        y_batch.append(y)\n","\n","    AtomicNum_batch = torch.cat(AtomicNum_batch)\n","    Edge_batch = torch.cat(Edge_batch, dim=1)\n","    Natom_batch = Natom_batch\n","    y_batch = torch.cat(y_batch)\n","\n","    return AtomicNum_batch, Edge_batch, Natom_batch, y_batch"]},{"cell_type":"markdown","metadata":{"id":"wV0z5HnIU9l6"},"source":["An example use of collate_graph."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":131,"status":"ok","timestamp":1709824077937,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"h-Uh-yivU_yz","outputId":"34394e9a-9f10-497f-9041-fba0c699d686"},"outputs":[],"source":["# Define graph 1\n","AtomicNum1 = torch.LongTensor([6, 6, 7])\n","Edge1 = torch.LongTensor([[0, 2, 2, 1],\n","                       [2, 0, 1, 2]])\n","Natom1 = 3\n","y1 =  torch.Tensor([74.18])\n","\n","# Define graph 2\n","AtomicNum2 = torch.LongTensor([6, 6, 8])\n","Edge2 = torch.LongTensor([[0, 2, 2, 1],\n","                       [2, 0, 1, 2]])\n","Natom2 = 3\n","y2 = torch.Tensor([64.32])\n","\n","graph1 = (AtomicNum1, Edge1, Natom1, y1)\n","graph2 = (AtomicNum2, Edge2, Natom2, y2)\n","\n","collate_graphs((graph1, graph2))"]},{"cell_type":"markdown","metadata":{"id":"ttrbU6KqVEEH"},"source":["Defining the train and test DataLoaders with the above functions."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":140,"status":"ok","timestamp":1709824079817,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"8QK75Q_ZVGxk"},"outputs":[],"source":["train_loader = DataLoader(train_dataset,\n","                          batch_size=512,\n","                          collate_fn=collate_graphs,shuffle=True)\n","\n","val_loader = DataLoader(val_dataset,\n","                          batch_size=512,\n","                          collate_fn=collate_graphs,shuffle=True)\n","\n","test_loader = DataLoader(test_dataset,\n","                          batch_size=512,\n","                          collate_fn=collate_graphs,shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"QIB1VXx4VL6b"},"source":["## 2.3 (20 points, grad) Complete the definition of a GNN"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":129,"status":"ok","timestamp":1709824082173,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"X52y1FuKVSSa"},"outputs":[],"source":["def scatter_add(src, index, dim_size, dim=-1, fill_value=0):\n","\n","    '''\n","    Sums all values from the src tensor into out at the indices specified in the index\n","    tensor along a given axis dim.\n","    '''\n","\n","    index_size = list(itertools.repeat(1, src.dim()))\n","    index_size[dim] = src.size(dim)\n","    index = index.view(index_size).expand_as(src)\n","\n","    dim = range(src.dim())[dim]\n","    out_size = list(src.size())\n","    out_size[dim] = dim_size\n","\n","    out = src.new_full(out_size, fill_value)\n","\n","    return out.scatter_add_(dim, index, src)"]},{"cell_type":"markdown","metadata":{"id":"Twd_HAJ0Vq3q"},"source":["Example usage of scatter_add()."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123,"status":"ok","timestamp":1709824084468,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"hDgs-8U7VsYi","outputId":"280a0c35-4e47-4d07-8fa6-fb12a622f4a5"},"outputs":[],"source":["# Say you have a graph with 4 nodes, and there are an edge list that describes their connectivities.\n","\n","Edge = torch.LongTensor([[0, 0, 1, 3], # index for i\n","                         [1, 2, 2, 0]]) # index for j\n","\n","# It means that the 0th node is connected to 1st node and the 2nd node; the 1st node is connected to the 2nd node.\n","# For now, let us assume the connections are directed, i.e. 0th node is connected the 1st node, but the 1st node is not connected to the 0th node.\n","# We want pass connection messages from the nodes in the first row to the nodes in the second row in Edge.\n","\n","# And for each edge, we have an message we wanto broadcast from i to j.\n","message_i2j = torch.Tensor([1000., 100., 10., 1.])\n","\n","# We can use scatter_add() function to aggregate these pairwise messages onto each node.\n","\n","node_message = scatter_add(src=message_i2j, # message array for all the directed edge\n","            index=Edge[1], # index to all the jth node to which you want to pass your message\n","            dim=0,         # feature dimension you want to sum over\n","            dim_size=4     # there are 4 nodes\n","            )\n","\n","print(node_message)\n","\n","# Now you can look at your results, you can see the messages are assigned from message_i2j to all the jth nodes you specified\n","\n","# see the graphical representation here: \"https://github.com/coleygroup/ML4MolEng/blob/main/psets/ps5/scatter_add_demo.png\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709824085696,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"LdFCk3l0Vx3L","outputId":"a021187d-c886-4a5f-d4ab-ddded3d73683"},"outputs":[],"source":["# If you want your graph to be undirected, i.e. the ith node is connected to the jth node and vice versa, you can perfrom the summation in both direction like this:\n","node_message = scatter_add(src=message_i2j, index=Edge[1], dim=0, dim_size=4) +  scatter_add(src=message_i2j, index=Edge[0], dim=0, dim_size=4)\n","\n","print(node_message)"]},{"cell_type":"markdown","metadata":{"id":"G5JOkK0qWD8U"},"source":["Example usage of torch.split()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1709824087961,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"qWOou2RzWCNj","outputId":"f743dfc4-20b2-490e-c48c-a99e4fc99586"},"outputs":[],"source":["tensor = torch.ones((5, 2))\n","splits_idx = [2, 3] # list of integers\n","print( torch.split(tensor, splits_idx) )\n","\n","# you have two tensors with size (2,2) and (3,2) respectively\n","for split in torch.split(tensor, splits_idx):\n","    print(split.shape)\n","\n","# And you can sum the spllited array separately and stack them together\n","print( torch.stack([split.sum(0) for split in torch.split(tensor, splits_idx)], dim=0) )"]},{"cell_type":"markdown","metadata":{"id":"bu59uoZOWJUs"},"source":["Your GNN class"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":176,"status":"ok","timestamp":1709824091403,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"WGtmvxosWIU2"},"outputs":[],"source":["class GNN(torch.nn.Module):\n","    '''\n","    A GNN model\n","    '''\n","    def __init__(self, n_convs=3, n_embed=64):\n","        super(GNN, self).__init__()\n","        # Declare 1 hot encoding\n","        self.atom_embed = nn.Embedding(100, n_embed)\n","        # Declare MLPs in a ModuleList\n","        self.convolutions = nn.ModuleList(\n","            [\n","                nn.ModuleDict({\n","                    'update_mlp': nn.Sequential(nn.Linear(n_embed, n_embed),\n","                                                nn.ReLU(),\n","                                                nn.Linear(n_embed, n_embed)),\n","                    'message_mlp': nn.Sequential(nn.Linear(n_embed, n_embed),\n","                                                 nn.ReLU(),\n","                                                 nn.Linear(n_embed, n_embed))\n","                })\n","                for _ in range(n_convs)\n","            ]\n","            )\n","        # Declare readout layers\n","        self.readout = nn.Sequential(nn.Linear(n_embed, n_embed), nn.ReLU(), nn.Linear(n_embed, 1))\n","\n","    def forward(self, AtomicNum, Edge, Natom):\n","\n","        # Parametrize embedding\n","        h = self.atom_embed(AtomicNum) #eqn. 1\n","\n","        ################ Code #################\n","\n","\n","        ################ Code #################\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"j7pwjIioXD5i"},"source":["### 2.4 (5 points, grad) Verify that your GNN preserves permutational invariance"]},{"cell_type":"markdown","metadata":{"id":"YMX6U9udXKIu"},"source":["Run this cell as is to show that your GNN respects permutational invariance."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1709824097969,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"T2U7X6peWNrz","outputId":"aeca24e3-331b-4685-fc40-8fb4a51e07a5"},"outputs":[],"source":["def permute_graph(z, a, perm):\n","    '''\n","        permute the order of nodes in a molecular graph\n","\n","        Args:\n","            z(np.array): atomic number array\n","            a(np.array): edge index pairs\n","\n","        Return:\n","            (np.array, np.array): permuted atomic number, and edge list\n","    '''\n","\n","    z = np.array(z)\n","    perm = np.array(perm)\n","    assert len(perm) == len(z)\n","\n","    z_perm = z[perm]\n","    a_perm = np.zeros(a.shape).astype(int)\n","\n","    for i, edge in enumerate(a):\n","        for j in range(len(edge)):\n","            indices = np.where(perm == edge[j])[0]\n","            if indices.size > 0:\n","                a_perm[i, j] = indices[0]\n","    return z_perm, a_perm\n","\n","# node input\n","z_orig = np.array([6, 6, 8, 7])\n","# edge input\n","a_orig = np.array([[0, 0, 1, 2, 3, 0], [1, 2, 0, 0, 0, 3]] )\n","\n","permutation = itertools.permutations([0, 1 ,2, 3])\n","device = 'cuda:0'\n","model = GNN(n_convs=4, n_embed=128).to(device)\n","model.eval()\n","\n","for perm in permutation:\n","    z_perm, a_perm = permute_graph(z_orig, a_orig, perm)\n","\n","    z = torch.LongTensor(z_perm).to(device)\n","    a = torch.LongTensor(a_perm).to(device)\n","    N = [z.shape[0]]\n","\n","    output = model(z, a, N).item()\n","\n","    print(\"model output: {:.5f} for perumutation: {}\".format(output, perm))"]},{"cell_type":"markdown","metadata":{"id":"XsluOOWpY9yh"},"source":["## 1.5 (10 points) Train and test your GNN"]},{"cell_type":"markdown","metadata":{"id":"MTrIEOlnyph6"},"source":["Undergrads uncomment this cell to get a GNN implementation based on the [torch_geometric GCN](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GCN.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Abrt4-fWymOo"},"outputs":[],"source":["'''\n","!pip install torch_geometric\n","import torch_geometric\n","\n","# Wrapper class around torch_geometic GCN to match expected inputs\n","class GNN(torch_geometric.nn.models.GCN):\n","    def __init__(self, n_convs=3, n_embed=64):\n","        # Intatiate GCN\n","        super(GNN, self).__init__(-1,n_embed,n_convs)\n","        # Declare 1 hot encoding\n","        self.atom_embed = nn.Embedding(100, n_embed)\n","        # Declare readout layers\n","        self.readout = nn.Sequential(nn.Linear(n_embed, n_embed), nn.ReLU(), nn.Linear(n_embed, 1))\n","    def forward(self, AtomicNum, Edge, Natom):\n","        # Parametrize embedding\n","        h = self.atom_embed(AtomicNum)\n","        # Graph convolutions\n","        h = super(GNN, self).forward(h,Edge)\n","        # Node wise output\n","        node_out = self.readout(h)\n","        # Split nodes back to graphs\n","        node_splits = torch.split(node_out, Natom)\n","        output = torch.stack([i.sum() for i in node_splits])\n","        return output\n","'''"]},{"cell_type":"markdown","metadata":{"id":"B-GzhmRjZPPO"},"source":["A combined train/validation loop, with progress bar."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":151,"status":"ok","timestamp":1709824593880,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"YOYpwGK7ZJzr"},"outputs":[],"source":["def loop(model, loader, epoch, evaluation=False):\n","\n","    if evaluation:\n","        model.eval()\n","        mode = \"eval\"\n","    else:\n","        model.train()\n","        mode = 'train'\n","    batch_losses = []\n","\n","    # Define tqdm progress bar\n","    tqdm_data = tqdm(loader, position=0, leave=False, desc='{} (epoch #{})'.format(mode, epoch))\n","\n","    for data in tqdm_data:\n","\n","        AtomicNumber, Edge, Natom, y = data\n","        AtomicNumber = AtomicNumber.to(device)\n","        Edge = Edge.to(device)\n","        y = y.to(device)\n","        pred = model(AtomicNumber, Edge, Natom)\n","        loss = (pred-y).pow(2).mean() # MSE loss\n","\n","        if not evaluation:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        batch_losses.append(loss.item())\n","\n","        postfix = ['batch loss={:.3f}'.format(loss.item()) ,\n","                   'avg. loss={:.3f}'.format(np.array(batch_losses).mean())]\n","\n","        tqdm_data.set_postfix_str(' '.join(postfix))\n","\n","    return np.array(batch_losses).mean()"]},{"cell_type":"markdown","metadata":{"id":"MP9Qq6JKZYx8"},"source":["Run this cell to train your model for 500 epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65925,"status":"ok","timestamp":1709824712915,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"Bxcd6HEUZOTc","outputId":"5083aa30-05d7-4ea6-ed11-45c86a48af24"},"outputs":[],"source":["from torch import optim\n","\n","device = 'cuda:0'\n","model = GNN(n_convs=4, n_embed=128).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=50, verbose=True)\n","\n","for epoch in range(10):\n","    train_loss = loop(model, train_loader, epoch)\n","    val_loss = loop(model, val_loader, epoch, evaluation=True)"]},{"cell_type":"markdown","metadata":{"id":"Nsu9OaLGaQ-p"},"source":["Function to evaluate the GNN"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1709823094518,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"jP0XlX-wbw6J"},"outputs":[],"source":["def evaluate(model, dataloader, device):\n","\n","    '''\n","    A function to return the predicted solubility (for evaluation).\n","\n","    Args:\n","        model (torch.nn.Module): your sequence classifier\n","        dataloader (torch.utils.data.Dataloader): DataLoader object for the train data\n","        device (str): Your device\n","\n","    Returns:\n","        (np.array, np.array): true values, predicted values\n","    '''\n","\n","    y_pred_list = []\n","    y_list = []\n","\n","    with torch.no_grad():\n","        model.eval()\n","        for batch in dataloader:\n","\n","            AtomicNumber, Edge, Natom, y = batch\n","            AtomicNumber = AtomicNumber.to(device)\n","            Edge = Edge.to(device)\n","            y = y.to(device)\n","            y_pred = model(AtomicNumber, Edge, Natom)\n","\n","            y_pred_list+=y_pred.detach().cpu().numpy().tolist()\n","            y_list+=y.detach().cpu().numpy().tolist()\n","\n","    return np.array(y_list), np.array(y_pred_list)"]},{"cell_type":"markdown","metadata":{"id":"_Z-AIs6Pc0i_"},"source":["Calculate train and test R^2 and generate a scatter plot comparing solubility to predicted solubility for train and test data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":501},"executionInfo":{"elapsed":3375,"status":"ok","timestamp":1709824306118,"user":{"displayName":"William Colgan","userId":"02556390937542447496"},"user_tz":300},"id":"3XieGpbtcvTN","outputId":"d5ed80d7-cff9-446d-9209-c64768fa7d4d"},"outputs":[],"source":["################ Code #################\n","\n","\n","################ Code #################\n","\n","print(\"The mean train R^2 is {:.2f}\".format(train_r2))\n","print(\"The mean test R^2 is {:.2f}\".format(test_r2))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PUzdxshZfrc"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
