{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center> Problem Set 6 <center>\n",
    "\n",
    "<center>  7.C01/7.C51, 20.C01/20.C51 <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting style, you can choose your own parameters\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "matplotlib.rc('lines', linewidth=3, color='g')\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams[\"xtick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 2\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 2\n",
    "matplotlib.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided the code to load the dataset. Take a moment to understand what each line is doing. Briefy explain what each line of the code is doing by providing short comments below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-drug-screen/data/prism_train.csv\n",
    "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-drug-screen/data/prism_test.csv\n",
    "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-drug-screen/data/prism_cell_line_metadata.csv\n",
    "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-drug-screen/data/prism_perturbation_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = pd.read_csv(\n",
    "    \"prism_train.csv\",\n",
    "    header=\"infer\",\n",
    "    index_col=0,\n",
    ")\n",
    "prism_test = pd.read_csv(\n",
    "    \"prism_test.csv\",\n",
    "    header=\"infer\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# Auxillary Datasets\n",
    "cell_line_info = pd.read_csv(\n",
    "    \"prism_cell_line_metadata.csv\",\n",
    "    header=\"infer\",\n",
    "    index_col=0,\n",
    ")\n",
    "treatment_info = pd.read_csv(\n",
    "    \"prism_perturbation_metadata.csv\",\n",
    "    header=\"infer\",\n",
    "    index_col=0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preliminary Data Cleaning & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prism.to_numpy()\n",
    "X = prism.index.to_list()\n",
    "X[:10], y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 (5 points) Compute Morgan Fingerprints For Each Molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "\n",
    "#########your implementation here######### \n",
    "\n",
    "# Use these methods:\n",
    "#    Chem.MolFromSmiles()\n",
    "#    AllChem.GetHashedMorganFingerprint() with radius = 2 & nBits=1024\n",
    "#    DataStructs.ConvertToNumpyArray()\n",
    "\n",
    "#########your implementation here#########\n",
    "\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 (2 points) Separate Dataset into Train / Val Splits (0.8 / 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3: (3 points) Perform Missing Data Imputation for the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "y_train_raw = y_train.copy() # Leave untouched for later visualizations\n",
    "print(\"We must impute this many missing cell values: \", np.isnan(y_train).sum())\n",
    "\n",
    "#########your implementation here#########\n",
    "\n",
    "#########your implementation here#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "plt.hist(\n",
    "    y_train_raw[~np.isnan(y_train)].flatten(),\n",
    "    bins=30,\n",
    "    alpha=0.5,\n",
    "    color=\"blue\",\n",
    "    label=\"raw y_train\",\n",
    ")\n",
    "plt.hist(\n",
    "    y_train.flatten(),\n",
    "    bins=30,\n",
    "    alpha=0.5,\n",
    "    color=\"green\",\n",
    "    label=\"imputed y_train\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Viability Fold Change\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "\n",
    "plt.title('Viability Fold Change')\n",
    "plt.ylabel(\"Cell Lines\")\n",
    "plt.xlabel(\"Chemical Perturbation\")\n",
    "img = plt.imshow(y_train.T, vmin=-2, vmax=2)\n",
    "fig.colorbar(img)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a few sentences detailing the task, insights on the data, and what models would be a good fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Baseline Prediction of Unseen Chemical Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(y_true, y_pred):\n",
    "    mask = ~np.isnan(y_true)  \n",
    "    mse = np.mean((y_true[mask] - y_pred[mask])**2) \n",
    "    rmse = np.sqrt(mse) \n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_pred, y_true, label='Eval RMSE: {:.4f}'.format(rmse))\n",
    "    plt.ylabel(\"True Value\")\n",
    "    plt.xlabel(\"Predicted Value\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 (10 points) Baseline with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 (10 points) Baseline with Neural Network Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: (70 points) Machine Learning Competition and Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(model, X_test, csv_name):\n",
    "    pred_df = pd.DataFrame(index=prism_test[\"SMILES\"], columns=prism.columns)\n",
    "    pred_df[:] = model.predict(X_test)\n",
    "    # Annoyingly Kaggle can't seem to handle large matrix datasets \n",
    "    # & so we need to cut down our submission to just the first 30 cell lines\n",
    "    pred_df.iloc[:, :30].to_csv(csv_name)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prism_test['SMILES'].to_list()\n",
    "new_X_test = []\n",
    "for smiles in tqdm(X_test):\n",
    "    morgan_fingerprints = AllChem.GetHashedMorganFingerprint(\n",
    "        Chem.MolFromSmiles(smiles), 2, nBits=1024\n",
    "    )\n",
    "    arr = np.zeros((0,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(morgan_fingerprints, arr)\n",
    "    new_X_test.append(np.array(arr))\n",
    "X_test = np.array(new_X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
