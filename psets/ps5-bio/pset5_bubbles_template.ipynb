{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kkhPENedrIBY"
      },
      "source": [
        "#  <center> Problem Set 5 Bubbles <center>\n",
        "<center> Spring 2024 <center>\n",
        "<center> 3.C01/3.C51, 7.C01/7.C51, 10.C01/10.C51, 20.C01/20.C51 <center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDflHQQQq8xR"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import glob \n",
        "import PIL\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from skimage import io, color\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn \n",
        "from torchvision.models import vgg16\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8yBK7f3rQTB"
      },
      "source": [
        "## Part 1: Classifying  Steel  Surface  Defects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leuQXRMgq8xS",
        "outputId": "49cce048-86b8-44bd-8ac6-cca7727f0e47"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps5/data/neu_surface_defects_jpeg.tar.gz\n",
        "!tar -xf neu_surface_defects_jpeg.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wx3QfJgr6i5"
      },
      "source": [
        "### 1.1 (15 points)  Build Image Datasets and DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn5mN2X5sZ0F"
      },
      "source": [
        "Get all the image filepaths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbJg37c-q8xV"
      },
      "outputs": [],
      "source": [
        "files = glob.glob(os.path.join('neu_surface_defects', \"*.jpg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOArZUkBsbSa"
      },
      "source": [
        "Visualize a random image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "L_Yld5X0q8xW",
        "outputId": "3a551563-bee5-4c76-84fa-c3ddd45b6269"
      },
      "outputs": [],
      "source": [
        "idx = 30\n",
        "img = Image.open(files[idx])\n",
        "print(files[idx])\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeVpYW7dtpBx"
      },
      "source": [
        "Your ImageDataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7GPTySeq8xd"
      },
      "outputs": [],
      "source": [
        "# dictionary labels \n",
        "label_dict = {\n",
        "'Cr': 0, \n",
        "'In': 1, \n",
        "'Pa': 2,\n",
        "'PS': 3, \n",
        "'RS': 4,\n",
        "'Sc': 5\n",
        "}\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        \n",
        "        '''\n",
        "        Image dataset object that loads and transforms images. \n",
        "        \n",
        "        '''\n",
        "        \n",
        "        self.paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ################ Code #################\n",
        "\n",
        "        # read images given file path \n",
        "        img = None\n",
        "        label = None\n",
        "\n",
        "        ################ Code #################\n",
        "\n",
        "        # transform images \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        sample = img, label\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQTPDMigt-8S"
      },
      "source": [
        "Transform your dataset, split the data, and define your Datasets and DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zuntd8Geq8xe"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wS0OCC1vbtH"
      },
      "source": [
        "### 1.2 (10 points) Understand the Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1dzgp-evj_f"
      },
      "source": [
        "Define and load a pretrained VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqqFfNldq8xh"
      },
      "outputs": [],
      "source": [
        "class VGG_fc1(nn.Module):\n",
        "    def __init__(self, weights):\n",
        "        super(VGG_fc1, self).__init__()\n",
        "        self.features = vgg16(weights=weights).features # convolutional layers\n",
        "        self.avgpool = vgg16(weights=weights).avgpool\n",
        "        self.fc1 = vgg16(weights=weights).classifier[0] # first layer of classifier\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"Extract first fully connected feature vector\"\"\"\n",
        "        # Apply convolutions\n",
        "        x = self.features(x)\n",
        "        # Apply pooling\n",
        "        x = self.avgpool(x)\n",
        "        # Flatten and convert to vectors\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "    \n",
        "model = VGG_fc1(weights = \"VGG16_Weights.DEFAULT\").eval() # turn model into evaluation mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L48QeOSvxMT"
      },
      "source": [
        "The model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F91GsLwYq8xh",
        "outputId": "83cdb542-7157-4505-b3c1-74e1fe36d1cf"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGslh0UfwJSy"
      },
      "source": [
        "Choose an image from your training set and visualize 4 channels in each of layers 1, 5, and 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Zvafh-q8xi"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOUaoMEhxStw"
      },
      "source": [
        "What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXXmqO_ZxUfF"
      },
      "outputs": [],
      "source": [
        "############### Answer #################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rvY4ZXNx2LV"
      },
      "source": [
        "### 1.3 (20 points) Train a Classifier with Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diWEWmh0yv3i"
      },
      "source": [
        "Define a VGG-based transfer learning classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsJjlS2Oq8xj"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frhG5yDOzR9y"
      },
      "source": [
        "Train your classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-vgXDpeq8xl"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l-xAHXc0B2B"
      },
      "source": [
        "Compute and plot a test confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt7vNi69q8xn"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 (grad, 5 points) Pre-training questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi9aP_5aq8xp"
      },
      "source": [
        "Why do you need to resize images to specific shapes and normalize pixel values to specific values for each color channel?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW39UCJH0R-p"
      },
      "outputs": [],
      "source": [
        "############### Answer #################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBMW_dhDq8xq"
      },
      "source": [
        "What are the benefits of transfer learning versus training the entire stack (CNN + MLP) again. What are the potential limitations of this approach? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcyCx8px0V2R"
      },
      "outputs": [],
      "source": [
        "############### Answer #################\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Dvhbowq8xq"
      },
      "source": [
        "### 1.5 (grad, 20 points) Obtain Saliency Maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3jO7M9t08d6"
      },
      "source": [
        "Compute the saliency map for two images of each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqdm8qjQq8xr"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOVo2G881kEv"
      },
      "source": [
        "Comment on any pattern you observe in the saliency maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJROOMbK2Tky"
      },
      "outputs": [],
      "source": [
        "############### Answer #################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul5oOjm02YrG"
      },
      "source": [
        "## Part 2: Image Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL8et7Ru3Ncd"
      },
      "source": [
        "### 2.1 (15 points) Build Datasets and DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2FZVtil3bEh"
      },
      "source": [
        "Download and unzip data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDMwe7rrq8xs",
        "outputId": "79444080-4e34-48fb-afac-68fcb709fe33"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps5/data/bubble_segmentation_jpeg.tar.gz\n",
        "!tar -xf bubble_segmentation_jpeg.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wYYnWT63cbh"
      },
      "source": [
        "Parse data from image filepaths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR1g3Tqfq8xt"
      },
      "outputs": [],
      "source": [
        "paths = [path for path in glob.glob(\"bubble_segmentation/*\") if \"bubbles\" in path]\n",
        "\n",
        "def load_img(path):\n",
        "    x = np.array(Image.open(path)) / 255\n",
        "    y = np.array(Image.open(path.replace(\"bubbles\",\"masks\"))) / 255\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FViLdxLB5l5t"
      },
      "source": [
        "Load one image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx = 20\n",
        "cells, masks = load_img(paths[idx])\n",
        "fig, axes = plt.subplots(1,2)\n",
        "axes[0].imshow(cells, cmap='gray')\n",
        "axes[1].imshow(masks, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYwO-Xak3zLw"
      },
      "source": [
        "Your ImageDataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zriwmkRAq8xu"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ND6VSEu7FX3"
      },
      "source": [
        "Split your data and load your DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31UV3F8mq8xu"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O4IXEpP7k95"
      },
      "source": [
        "Is it necessary to apply random translation to your images?  Briefly justify your answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "############### Answer #################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-JdNjZnq8xv"
      },
      "source": [
        "### 2.2 (20 points) Train a U-Net Model that Performs Image Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt8MmtP-8J3J"
      },
      "source": [
        "Implement Dice loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WwT8lRfq8xw"
      },
      "outputs": [],
      "source": [
        "def dice_loss(pred, target):\n",
        "    \"\"\"Calculate Dice loss.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        pred:\n",
        "            predictions from the model\n",
        "        target:\n",
        "            ground truth label\n",
        "    \"\"\"\n",
        "\n",
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxVWrdqH8Sst"
      },
      "source": [
        "The U-Net Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmx2n7Frq8xw"
      },
      "outputs": [],
      "source": [
        "class DownSampling(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, name=None):\n",
        "        super(DownSampling, self).__init__()\n",
        "\n",
        "        self.conv = ConvBlock(in_channels, out_channels, kernel_size)\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        conv_out = self.conv(x)\n",
        "        output = self.max_pool(conv_out)\n",
        "\n",
        "        return output, conv_out\n",
        "\n",
        "\n",
        "class UpSampling(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, name=None):\n",
        "        super(UpSampling, self).__init__()\n",
        "\n",
        "        self.conv = ConvBlock(in_channels, out_channels, kernel_size)\n",
        "        self.conv_t = nn.ConvTranspose2d(out_channels, out_channels, kernel_size, \\\n",
        "                                         padding=1, stride=2, output_padding=1)\n",
        "\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "\n",
        "        conv_out = self.conv(x)\n",
        "        output = self.conv_t(conv_out)\n",
        "\n",
        "        output += skip\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding=1, stride=1, name=None):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        block = []\n",
        "        # first conv layer\n",
        "        block.append(nn.Conv2d(in_channels, out_channels, kernel_size, \\\n",
        "                               padding=padding, stride=stride))\n",
        "        block.append(nn.ReLU())\n",
        "        block.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # second conv layer\n",
        "        block.append(nn.Conv2d(out_channels, out_channels, kernel_size, \\\n",
        "                               padding=padding, stride=stride))\n",
        "        block.append(nn.ReLU())\n",
        "        block.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # make sequential\n",
        "        self.conv_block = nn.Sequential(*block)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        output = self.conv_block(x)\n",
        "\n",
        "        return output\n",
        "    \n",
        "    \n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_kernel=8, kernel_size=3, dim=1, target_dim=1):\n",
        "        \"\"\"UNet\n",
        "\n",
        "        Arguments:\n",
        "            num_kernel: int\n",
        "                number of kernels to use for the first layer\n",
        "            kernel_size: int\n",
        "                size of the kernel for the first layer\n",
        "            dims: int\n",
        "                number of color channels for input images \n",
        "            target_dim: int \n",
        "                number of channels for the output mask\n",
        "        \"\"\"\n",
        "\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.num_kernel = num_kernel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dim = dim\n",
        "        self.target_dim = 1\n",
        "\n",
        "        # encode\n",
        "        self.encode_1 = DownSampling(self.dim, num_kernel, kernel_size)\n",
        "        self.encode_2 = DownSampling(num_kernel, num_kernel*2, kernel_size)\n",
        "        self.encode_3 = DownSampling(num_kernel*2, num_kernel*4, kernel_size)\n",
        "        self.encode_4 = DownSampling(num_kernel*4, num_kernel*8, kernel_size)\n",
        "\n",
        "        # bridge\n",
        "        self.bridge = nn.Conv2d(num_kernel*8, num_kernel*16, kernel_size, padding=1, stride=1)\n",
        "\n",
        "        # decode\n",
        "        self.decode_4 = UpSampling(num_kernel*16, num_kernel*8, kernel_size)\n",
        "        self.decode_3 = UpSampling(num_kernel*8, num_kernel*4, kernel_size)\n",
        "        self.decode_2 = UpSampling(num_kernel*4, num_kernel*2, kernel_size)\n",
        "        self.decode_1 = UpSampling(num_kernel*2, num_kernel, kernel_size)\n",
        "\n",
        "        self.segment = nn.Conv2d(num_kernel, self.target_dim, 1, padding=0, stride=1)\n",
        "        self.activate = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        has_channel = x.ndim == 4\n",
        "        if not has_channel:\n",
        "            x = x.unsqueeze(1)\n",
        "            \n",
        "        x, skip_1 = self.encode_1(x)\n",
        "        x, skip_2 = self.encode_2(x)\n",
        "        x, skip_3 = self.encode_3(x)\n",
        "        x, skip_4 = self.encode_4(x)\n",
        "\n",
        "        x = self.bridge(x)\n",
        "\n",
        "        x = self.decode_4(x, skip_4)\n",
        "        x = self.decode_3(x, skip_3)\n",
        "        x = self.decode_2(x, skip_2)\n",
        "        x = self.decode_1(x, skip_1)\n",
        "\n",
        "        x = self.segment(x)\n",
        "\n",
        "        pred = self.activate(x)\n",
        "\n",
        "        if not has_channel:\n",
        "            pred = pred.squeeze(1)\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "    def args_dict(self):\n",
        "        \"\"\"model arguments to be saved\n",
        "        \"\"\"\n",
        "\n",
        "        model_args = {'dim': self.dim,\n",
        "                      'target_dim': self.target_dim,\n",
        "                      'num_kernel' : self.num_kernel,\n",
        "                      'kernel_size' : self.kernel_size}\n",
        "\n",
        "        return model_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AcPtMe29Rr0"
      },
      "source": [
        "Example model usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1cbgiuw9VMz",
        "outputId": "273b1e3d-2a59-4d75-8c3f-1235e2fa9291"
      },
      "outputs": [],
      "source": [
        "model = UNet()\n",
        "y = model(torch.randn(4, 256, 256))\n",
        "\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLG1gczo9YbG"
      },
      "source": [
        "A function to plot a segmentation map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llCt40io9Yuu"
      },
      "outputs": [],
      "source": [
        "def plot_seg(img, pred_seg, true_seg, mask_cutoff=0.5):\n",
        "\n",
        "    \"\"\" Visualize segmentation results.\n",
        "    Inputs:\n",
        "        image: orginal image, shape: 256 x 256\n",
        "        pred_seg: predicted mask, shape: 256 x 256 \n",
        "        true_seg: true mask, shape: 256 x 256\n",
        "        mask_cutoff: if the mask values is larger than mask_cutoff, the mask will appear on the image\n",
        "    \"\"\"\n",
        "    img = img.squeeze()\n",
        "    pred_seg = pred_seg.squeeze()\n",
        "    true_seg = true_seg.squeeze()\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, sharex='col', sharey='row')\n",
        "    fig.set_size_inches((15,15))\n",
        "    \n",
        "    ax[0].set_title(\"Original Image\")\n",
        "    ax[1].set_title(\"Prediction\")\n",
        "    ax[2].set_title(\"Ground Truth\")\n",
        "    \n",
        "    img = np.stack([img,img,img],axis = -1)\n",
        "    ax[0].imshow(img)\n",
        "    ax[1].imshow(np.clip(color.label2rgb(pred_seg > mask_cutoff,img,colors=[(255,0,0)],alpha=0.0025, bg_label=0, bg_color=None),0,1))\n",
        "    ax[2].imshow(np.clip(color.label2rgb(true_seg > mask_cutoff,img,colors=[(255,0,0)],alpha=0.0025, bg_label=0, bg_color=None),0,1))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A9wkLRv9eNm"
      },
      "source": [
        "Train your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KIBOgn6q8xy"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIzNNYYY-kuB"
      },
      "source": [
        "Show segmentation results for 3 images from the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f6mY8R6x-mY8",
        "outputId": "e3f67839-e82b-4dee-a8ce-a4e1abd145e9"
      },
      "outputs": [],
      "source": [
        "################ Code #################\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4wS0OCC1vbtH",
        "6rvY4ZXNx2LV",
        "U3Dvhbowq8xq",
        "L-JdNjZnq8xv"
      ],
      "name": "pset5_solutions.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
