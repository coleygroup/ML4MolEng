{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7GytPTqFVce"
   },
   "source": [
    "#  <center> Problem Set 4 <center>\n",
    "\n",
    "<center> 7.C01/7.C51 & 20.C01/20.C51 <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLudDlXUFVcf"
   },
   "source": [
    "<b>Name:</b>\n",
    "\n",
    "<b>Kerberos id:</b>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Setup\n",
    "import sys\n",
    "# !{sys.executable} -m pip install rdkit\n",
    "# !{sys.executable} -m pip install molvs\n",
    "\n",
    "!pip install rdkit\n",
    "!pip install molvs\n",
    "!pip install wget\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hjb_wAuFuefD",
    "outputId": "9fca51bb-5627-494e-fb81-aa5ab22e99e6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from molvs import standardize_smiles\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import wget\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm \n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "matplotlib.rc('lines', linewidth=3, color='g')\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams[\"xtick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 2\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 2\n",
    "matplotlib.rcParams['text.usetex'] = False"
   ],
   "metadata": {
    "id": "5QR5L11IFaAr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "_______"
   ],
   "metadata": {
    "id": "MZB9EKkrThFC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Dimensionality Reduction for Molecular Representations"
   ],
   "metadata": {
    "id": "61WWOvz9IjIo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Download data\n",
    "path = \"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/bio_version/jak2.csv\"\n",
    "wget.download(path, \"./\")"
   ],
   "metadata": {
    "id": "tLn8uvVaFaDg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Load data\n",
    "jak2 = pd.read_csv(\"jak2.csv\")"
   ],
   "metadata": {
    "id": "1ZWFWBecQqfq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Convert SMILES strings to Morgan fingerprints with rdkit\n",
    "# Define radius and number of bits for our exercise\n",
    "radius_pset4 = 3\n",
    "num_bits_pset4 = 2048\n",
    "\n",
    "class ECFP:\n",
    "    def __init__(self, smiles):\n",
    "        self.mols = [Chem.MolFromSmiles(i) for i in smiles]\n",
    "        self.smiles = smiles\n",
    "\n",
    "    def mol2fp(self, mol):\n",
    "        bi = {}\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol,\n",
    "                                                   radius = radius_pset4,\n",
    "                                                   bitInfo = bi,\n",
    "                                                   nBits = num_bits_pset4)\n",
    "        array = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fp, array)\n",
    "        return array, bi\n",
    "\n",
    "    def compute_ECFP(self):\n",
    "        bit_headers = ['bit' + str(i) for i in range(num_bits_pset4)]\n",
    "        arr = np.empty((0,num_bits_pset4), int).astype(int)\n",
    "        bitInfo_all = []\n",
    "        mol_all = []\n",
    "        for i in self.mols:\n",
    "            mol_all.append(i)\n",
    "            fp, bi = self.mol2fp(i)\n",
    "            arr = np.vstack((arr, fp))\n",
    "            bitInfo_all.append(bi)\n",
    "        df_fp = pd.DataFrame(np.asarray(arr).astype(int),columns=bit_headers)\n",
    "        df_fp.insert(loc=0, column='smiles', value=self.smiles)\n",
    "        df_fp.insert(loc=1, column='mol', value=mol_all)\n",
    "        df_fp.insert(loc=2, column='bitInfo', value=bitInfo_all)\n",
    "        return df_fp\n",
    "\n",
    "smiles_standarized = [standardize_smiles(i) for i in jak2['SMILES'].values]\n",
    "jak2_fp_descriptor = ECFP(smiles_standarized)\n",
    "jak2_fp = jak2_fp_descriptor.compute_ECFP()\n",
    "# Remove first column as we will reference smiles column from \"jak2\" dataframe\n",
    "# Remove second and third columns because not needed for our exercise here\n",
    "jak2_fp = jak2_fp.drop(columns=['smiles', 'mol', 'bitInfo'])\n",
    "# This resulting dataframe, jak2_fp, contains the 2048 bits (columns) making up\n",
    "# the fingerprints for the 1,911 molecules (rows)"
   ],
   "metadata": {
    "id": "IR4w1bbwuGrH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 (5 points, Grad students only) Choosing radius and number of bits for Morgan fingerprints\n"
   ],
   "metadata": {
    "id": "sTxdaB3VSn8Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Provide a one-sentence description of what the radius represents and another of what the number of bits represents. How does adjusting the radius parameter affect the granularity of the motifs captured by the fingerprints, and how does this relate to the choice of the number of bits?"
   ],
   "metadata": {
    "id": "ZTQtvKLYTaPy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "id": "YKIeIhaISy13"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 (10 points) Principal Component Analysis on Molecular Fingerprints"
   ],
   "metadata": {
    "id": "b1zAbOuNfh8Y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform PCA to reduce data into vectors of 100 dimensions. Visualize the first two components of your data in  a 2D scatter plot and color each molecule by its pIC50."
   ],
   "metadata": {
    "id": "P0pPfbnRSgKt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Modify this code chunk ##########\n",
    "# Perform PCA\n",
    "\n",
    "\n",
    "# Skeleton code for plotting\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sc = ax.scatter(, , s=3, c=jak2['pIC50'], cmap='viridis')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('pIC50', rotation=270, labelpad=15)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "zlH4qvVYauIj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the explained variance ratio of the 100 principal components?"
   ],
   "metadata": {
    "id": "5TQ7lzWW2AM1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "qBscO023VpHD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "What patterns do you observe?"
   ],
   "metadata": {
    "id": "Z1--fjSR2YZf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "id": "jK3FGHXVV4Wz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 (10 points) t-SNE analysis on Molecular Fingerprints"
   ],
   "metadata": {
    "id": "BsOdKOy-3M6S"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform t-SNE on the obtained principal components, with perplexity value of 2, 30, and 500. Plot the results and label your plots."
   ],
   "metadata": {
    "id": "_b_CFYcx3VoJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "i5NPXALUWFQp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "What differences do you see between the 3 t-SNE plots? What patterns do you observe in the perplexity = 30 plot?"
   ],
   "metadata": {
    "id": "yn2OqHjA7Ojz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "id": "tFKbo_JmWOCT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 (20 points, Grad students only) Are the low dimensional embeddings meaningful?"
   ],
   "metadata": {
    "id": "PRjTx6D_8vko"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Discretize pIC50 data by classifying any molecule with a pIC50 value >= 9.5 as effective (i.e., 1) and any with <9.5 as ineffective (i.e., 0). Append this as a new column called `is_effective` to the `jak2` dataframe."
   ],
   "metadata": {
    "id": "Se7yVTLlFHkx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "_vdgujjtXFMc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data into 10 folds. For each fold, train on the other 9 folds and validate on the last fold. Record your prediction."
   ],
   "metadata": {
    "id": "2Gm0wuFA8xTp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "WEdfyqfNXH7b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classify your predictions into True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN)."
   ],
   "metadata": {
    "id": "-zBr6qGVCl41"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "pbASxfQfXOPt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the 2D t-SNE embeddings (perplexity = 30) colored by the four classification classes."
   ],
   "metadata": {
    "id": "MyTwfhNrDJeQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "QHK_9hyyXQLB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "What pattern do you observe?"
   ],
   "metadata": {
    "id": "hUjMCLOBILjX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "id": "FkvLD0h9XWV8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "________"
   ],
   "metadata": {
    "id": "IONMmMxeXb7-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Variational auto-encoders (VAEs) for proteins"
   ],
   "metadata": {
    "id": "qGg0j7f9Tp0l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Download data\n",
    "paths = [\n",
    "    \"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/bio_version/luxA_train.csv\",\n",
    "    \"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/bio_version/luxA_val.csv\",\n",
    "    \"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/bio_version/luxA_test.csv\"\n",
    "    ]\n",
    "\n",
    "for path in paths:\n",
    "    wget.download(path, \"./\")"
   ],
   "metadata": {
    "id": "NpWZkRTgX8Vh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Load data\n",
    "luxA_train = pd.read_csv(\"luxA_train.csv\")\n",
    "luxA_val = pd.read_csv(\"luxA_val.csv\")\n",
    "luxA_test = pd.read_csv(\"luxA_test.csv\")"
   ],
   "metadata": {
    "id": "LggWdumUlmX4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Character list for FASTA protein sequences\n",
    "aa_charset = ['-', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K',\n",
    "              'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "# Define encoder\n",
    "enc = preprocessing.LabelEncoder().fit(aa_charset)\n",
    "\n",
    "# Determine max length of protein sequences\n",
    "# Note that all have already been padded to have equivalent length\n",
    "max_len = len(luxA_train.aa_sequence[0]) # 360"
   ],
   "metadata": {
    "id": "p96gq4vtbWIO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 (5 points) Encode protein sequences into numerical vectors"
   ],
   "metadata": {
    "id": "0mmYyiOSZd-X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encode FASTA sequences into categorical vectors to make train/validation/test Datasets and DataLoaders."
   ],
   "metadata": {
    "id": "WTqfKy2Ko_0R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"########## Modify this code chunk ##########\n",
    "\n",
    "X_train = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_val = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = None\n",
    "train_loader = None\n",
    "\n",
    "val_data = None\n",
    "val_loader = None\n",
    "\n",
    "test_data = None\n",
    "test_loader = None\n"
   ],
   "metadata": {
    "id": "Q38RoK1KomrQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 (15 points) Implement the reparametrization trick for VAE"
   ],
   "metadata": {
    "id": "1OjRN6U0x13u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Modify this code chunk in the indicated places ##########\n",
    "# Protein VAE model\n",
    "\n",
    "class ProteinVAE(nn.Module):\n",
    "    def __init__(self, rnn_enc_hid_dim, enc_nconv,\n",
    "                 encoder_hid, z_dim,\n",
    "                 rnn_dec_hid_dim, dec_nconv, aa_seq_len, nchar\n",
    "                 ):\n",
    "        '''\n",
    "            Protein VAE model\n",
    "\n",
    "                rnn_enc_hid_dim: hidden dimension for the GRU encoder\n",
    "                enc_nconv: number of recurrent layers for the GRU decoder\n",
    "                encoder_hid: dimension of GRU encoder readout\n",
    "                z_dim: number of latent variable\n",
    "                rnn_dec_hid_dim: hidden dimension for the GRU decoder\n",
    "                dec_nconv: number of recurrent layers for the GRU decoder\n",
    "                aa_seq_len: total length of aligned amino acid sequences\n",
    "                nchar: number of possible characters\n",
    "\n",
    "        '''\n",
    "\n",
    "        super(ProteinVAE, self).__init__()\n",
    "\n",
    "        self.aa_seq_len = aa_seq_len\n",
    "        self.nchar = nchar\n",
    "        # Embedding layer\n",
    "        self.embed = nn.Embedding(self.nchar, rnn_enc_hid_dim)\n",
    "        # Encoding GRU\n",
    "        self.rnn_enc = nn.GRU(rnn_enc_hid_dim, rnn_enc_hid_dim, enc_nconv, batch_first=True)\n",
    "        # MLP to transfrom hidden output from Encoding GRU\n",
    "        self.mlp0 = nn.Linear(rnn_enc_hid_dim, encoder_hid)\n",
    "        # Network to parametrize mu\n",
    "        self.mu_network = nn.Linear(encoder_hid, z_dim)\n",
    "        # Network to parametrize log variance\n",
    "        self.logvar_network = nn.Linear(encoder_hid, z_dim)\n",
    "        # Decoding GRU\n",
    "        self.rnn_dec = nn.GRU(z_dim, rnn_dec_hid_dim, dec_nconv, batch_first=True)\n",
    "        # Output SMILES characters\n",
    "        self.readout = nn.Linear(rnn_dec_hid_dim, self.nchar)\n",
    "\n",
    "    def encode(self, x):\n",
    "        '''Output mean and log variance of the encoded SMILES'''\n",
    "        output, hn = self.rnn_enc(x)\n",
    "        h = torch.nn.functional.relu(self.mlp0(hn[-1]))\n",
    "        return self.mu_network(h), self.logvar_network(h)\n",
    "\n",
    "    def get_std(self, logvar):\n",
    "        '''Transform log variance to standard deviation'''\n",
    "        ################ Your code #################\n",
    "\n",
    "    def reparametrize(self, mu, std):\n",
    "        '''The reparametrization trick'''\n",
    "        if self.training:\n",
    "            ################ Your code #################\n",
    "\n",
    "\n",
    "            return z\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        '''Decoder to reconstruct latent variable back to SMILES'''\n",
    "        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, self.aa_seq_len, 1)\n",
    "        out, h = self.rnn_dec(z)\n",
    "        out_reshape = out.contiguous().view(-1, out.size(-1))\n",
    "\n",
    "        y0 = self.readout(out_reshape)\n",
    "        y = y0.contiguous().view(out.size(0), -1, y0.size(-1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embed(x) # Get SMILES embedding\n",
    "        mu, logvar = self.encode(x_embed) # Encoding SMILES to latent representations\n",
    "        std = self.get_std(logvar) # Transfrom log variance to std.\n",
    "        z = self.reparametrize(mu, std) # Reparametrization trick\n",
    "        smiles_recon = self.decode(z)  # Reconstruct SMILES string\n",
    "        return smiles_recon, mu, std"
   ],
   "metadata": {
    "id": "y4fCukcLcUOK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test your model by comparing your sampling with N(0, 1)."
   ],
   "metadata": {
    "id": "fhOGQeZGx4oO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Define your model\n",
    "model = ProteinVAE(rnn_enc_hid_dim=256, enc_nconv=1,\n",
    "                   encoder_hid=256, z_dim=128, rnn_dec_hid_dim=512,\n",
    "                   dec_nconv=3, nchar=len(aa_charset), aa_seq_len=max_len)\n",
    "\n",
    "# Compare your sampling with N(0, 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "sample = model.reparametrize(torch.zeros(1000), torch.ones(1000))\n",
    "plt.hist(sample.detach().cpu().numpy(), density=True)\n",
    "\n",
    "# Plot between -10 and 10 with .001 steps.\n",
    "x_axis = np.arange(-7, 7, 0.001)\n",
    "plt.plot(x_axis, norm.pdf(x_axis,0,1)) # Mean = 0, SD = 1.\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "Rj4b9sm_lmfD",
    "outputId": "30a30ea9-7fdb-4aae-e07a-d46e5643a019"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 (10 points) Implement the protein VAE loss function"
   ],
   "metadata": {
    "id": "zdsur7r8x7DC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement your loss function here."
   ],
   "metadata": {
    "id": "Mgq02V9ax807"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Modify this code chunk ##########\n",
    "def loss_function(recon_x, x, mu, std):\n",
    "    BCE =\n",
    "    KLD =\n",
    "    return BCE, KLD\n"
   ],
   "metadata": {
    "id": "1I5wK52JrLvW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 (5 points) Train your model"
   ],
   "metadata": {
    "id": "uOCXfVwWx_U6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simply run the following code chunks to train your model."
   ],
   "metadata": {
    "id": "Pq0Qvdz2yA0E"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "def loop(model, loader, epoch, beta=0.05, evaluation=False):\n",
    "    '''\n",
    "        Train/test your VAE model\n",
    "    '''\n",
    "\n",
    "    if evaluation:\n",
    "        model.eval()\n",
    "        mode = \"eval\"\n",
    "    else:\n",
    "        model.train()\n",
    "        mode = 'train'\n",
    "    batch_losses = []\n",
    "\n",
    "    tqdm_data = tqdm(loader, position=0, leave=True, desc='{} (epoch #{})'.format(mode, epoch))\n",
    "    for data in tqdm_data:\n",
    "\n",
    "        x = data[0].to(device)\n",
    "        recon_batch, mu, std = model(x)\n",
    "        loss_recon, loss_kl = loss_function(recon_batch, x, mu, std)\n",
    "        loss = loss_recon + beta * loss_kl\n",
    "\n",
    "        if not evaluation:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        postfix = ['recon loss={:.3f}'.format(loss_recon.item()) ,\n",
    "                   'KL loss={:.3f}'.format(loss_kl.item()) ,\n",
    "                   'total loss={:.3f}'.format(loss.item()) ,\n",
    "                   'avg. loss={:.3f}'.format(np.array(batch_losses).mean())]\n",
    "\n",
    "        tqdm_data.set_postfix_str(' '.join(postfix))\n",
    "\n",
    "    return np.array(batch_losses).mean()"
   ],
   "metadata": {
    "id": "OpeCBDNzlmjj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "device = 0\n",
    "\n",
    "model = ProteinVAE(rnn_enc_hid_dim=256, enc_nconv=1,\n",
    "                   encoder_hid=256, z_dim=128, rnn_dec_hid_dim=512,\n",
    "                   dec_nconv=3, nchar=len(aa_charset), aa_seq_len=max_len)\n",
    "\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "id": "W3RE8u5EbWMe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)"
   ],
   "metadata": {
    "id": "kjhYaK_JyDWn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4901c83c-2fe0-4388-9e71-a301526648af"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optional: mount your Google Drive to save your model and files."
   ],
   "metadata": {
    "id": "TdFtXp7g4Ynv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Optional: simply run this chunk ##########\n",
    "# Optional: mount your google drive to save model and files\n",
    "# Uncomment below lines if of interest\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#mydrive = '/content/drive/MyDrive'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JjmPyGu4WqO",
    "outputId": "21348128-ab62-40fb-e878-b2dc9ed63163"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Takes 35 minutes\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "\n",
    "    # sample_recon(model, epoch, val_loader, enc)\n",
    "    train_loss = loop(model, train_loader, epoch, 0.001)\n",
    "    val_loss = loop(model, val_loader, epoch, 0.001,  evaluation=True)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # optional: save model\n",
    "    # uncoment to save model if of interest\n",
    "    #if epoch % 15 == 0:\n",
    "    #     torch.save(model.state_dict(),\n",
    "    #             '{}/vae-{:03d}-{:.2f}.pth'.format(mydrive, epoch, train_loss))\n",
    "\n",
    "    #     torch.save(optimizer.state_dict(),\n",
    "    #         '{}/optim-{:03d}-{:.2f}.pth'.format(mydrive, epoch, train_loss))\n",
    "\n",
    "    if epoch == 0:\n",
    "        best_loss = train_loss.item()\n",
    "    else:\n",
    "        if train_loss.item() < best_loss:\n",
    "            best_loss = train_loss.item()"
   ],
   "metadata": {
    "id": "-ipDwZY0yDZQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ac70c660-ce17-442d-895f-232416b5469a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 (20 points) Sample new protein sequences"
   ],
   "metadata": {
    "id": "nLBs7aJX9L1b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A helper function for you."
   ],
   "metadata": {
    "id": "qYOtXvV09L3-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Helper function\n",
    "def index2fasta(mol_index, enc):\n",
    "    '''Transform your array of character indices back to FASTA'''\n",
    "    fasta_charlist = enc.inverse_transform(np.array(mol_index))\n",
    "    fasta = ''.join(fasta_charlist).strip(\" \")\n",
    "\n",
    "    return fasta"
   ],
   "metadata": {
    "id": "1PCB95bWyDeI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Randomly select two FASTA sequences in your test data, interpolate 10 points between them, and decode those points."
   ],
   "metadata": {
    "id": "Tnwkkafb9Q07"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Modify this code chunk ##########\n",
    "# select a starting and ending protein sequence\n",
    "\n",
    "start = index2fasta(test_loader.dataset.__getitem__(random.choices(range(len(test_loader.dataset)), k=1))[0].numpy().reshape(-1), enc)\n",
    "end = index2fasta(test_loader.dataset.__getitem__(random.choices(range(len(test_loader.dataset)), k=1))[0].numpy().reshape(-1), enc)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "################ Your code #################\n",
    "\n"
   ],
   "metadata": {
    "id": "WrYMISXutR_p"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Produce a scatter plot with the first two dimensions of $z$ of your test molecules and newly sampled molecules in the same figure. Color differently the test points and generated points."
   ],
   "metadata": {
    "id": "Fq0QyFqts_oN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "oyJll5jIvsbd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In a separate table, print the 10 different FASTA sequences you generated."
   ],
   "metadata": {
    "id": "nM8UaNe8tEWo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "id": "A8kXs-sGvv4l"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Briefly comment on the sequence diversity you observe among these 10 generated sequences. How many are essentially identical? What do you think can be done to improve the model in its ability to finely interpolate sequences in this learned latent space?"
   ],
   "metadata": {
    "id": "YYZBTcHsvzo4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "id": "egypYO1lwCWT"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
