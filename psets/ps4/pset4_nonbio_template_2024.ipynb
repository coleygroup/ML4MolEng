{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xlOtIehkfv94"
   },
   "source": [
    "#  <center> Problem Set 4 <center>\n",
    "<center> Spring 2024 <center>\n",
    "<center> 3.C01/3.C51, 10.C01/10.C51 <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-ST-K4gfv98"
   },
   "source": [
    "<b>Name:</b>\n",
    "\n",
    "<b>Kerberos id:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pk5qQd7fsEcw",
    "ExecuteTime": {
     "end_time": "2024-03-21T18:25:24.676059800Z",
     "start_time": "2024-03-21T18:25:07.935410300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\mateo\\anaconda3\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: molvs in c:\\users\\mateo\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\mateo\\anaconda3\\lib\\site-packages (from molvs) (1.16.0)\n",
      "Requirement already satisfied: rdkit in c:\\users\\mateo\\anaconda3\\lib\\site-packages (2022.9.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\mateo\\anaconda3\\lib\\site-packages (from rdkit) (1.24.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mateo\\anaconda3\\lib\\site-packages (from rdkit) (10.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!pip install molvs\n",
    "!pip install rdkit\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import wget\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import pandas as pd\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch import optim\n",
    "from molvs import standardize_smiles\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "matplotlib.rc('lines', linewidth=3, color='g')\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams['axes.linewidth'] = 2.0\n",
    "matplotlib.rcParams[\"xtick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.size\"] = 6\n",
    "matplotlib.rcParams[\"ytick.major.width\"] = 2\n",
    "matplotlib.rcParams[\"xtick.major.width\"] = 2\n",
    "matplotlib.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzJZLo1_fv-T"
   },
   "source": [
    "## Part 1: Dimensionality Reduction for Molecular Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhgzEPQ7fv-T",
    "outputId": "359930f0-26c4-43ef-bb34-5237b6936b15"
   },
   "outputs": [],
   "source": [
    "wget.download(\"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/nonbio_version/drug.csv\", \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cQj9wKbfv-T"
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "df = pd.read_csv(\"drug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Simply run this chunk ##########\n",
    "# Convert SMILES strings to Morgan fingerprints with rdkit\n",
    "# Define radius and number of bits for our exercise\n",
    "radius_pset4 = 3\n",
    "num_bits_pset4 = 512\n",
    "\n",
    "class ECFP:\n",
    "    def __init__(self, smiles):\n",
    "        self.mols = [Chem.MolFromSmiles(i) for i in smiles]\n",
    "        self.smiles = smiles\n",
    "\n",
    "    def mol2fp(self, mol):\n",
    "        bi = {}\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol,\n",
    "                                                   radius = radius_pset4,\n",
    "                                                   bitInfo = bi,\n",
    "                                                   nBits = num_bits_pset4)\n",
    "        array = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fp, array)\n",
    "        return array, bi\n",
    "\n",
    "    def compute_ECFP(self):\n",
    "        bit_headers = ['bit' + str(i) for i in range(num_bits_pset4)]\n",
    "        arr = np.empty((0,num_bits_pset4), int).astype(int)\n",
    "        bitInfo_all = []\n",
    "        mol_all = []\n",
    "        for i in self.mols:\n",
    "            mol_all.append(i)\n",
    "            fp, bi = self.mol2fp(i)\n",
    "            arr = np.vstack((arr, fp))\n",
    "            bitInfo_all.append(bi)\n",
    "        df_fp = pd.DataFrame(np.asarray(arr).astype(int),columns=bit_headers)\n",
    "        df_fp.insert(loc=0, column='smiles', value=self.smiles)\n",
    "        df_fp.insert(loc=1, column='mol', value=mol_all)\n",
    "        df_fp.insert(loc=2, column='bitInfo', value=bitInfo_all)\n",
    "        return df_fp\n",
    "\n",
    "smiles_standarized = [standardize_smiles(i) for i in df['SMILES'].values]\n",
    "fp_descriptor = ECFP(smiles_standarized)\n",
    "fp = fp_descriptor.compute_ECFP()\n",
    "# Remove first column as we will reference smiles column from df dataframe\n",
    "# Remove second and third columns because not needed for our exercise here\n",
    "fp = fp.drop(columns=['smiles', 'mol', 'bitInfo']).values.astype(float)\n",
    "# This resulting dataframe, fp, contains the 512 bits (columns) making up\n",
    "# the fingerprints for the 4,629 molecules (rows)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 (5 points, Grad students only) Choosing radius and number of bits for Morgan fingerprints\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Provide a one-sentence description of what the radius represents and another of what the number of bits represents. How does adjusting the radius parameter affect the granularity of the motifs captured by the fingerprints, and how does this relate to the choice of the number of bits?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLHmaf8Vfv-U"
   },
   "source": [
    "### 1.2 (10 points) Principal Component Analysis on Molecular Fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnjV1UK5fv-U"
   },
   "source": [
    "Perform PCA to reduce data into vectors of 100 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "pWm78Z--fv-U",
    "outputId": "17fb370d-ce53-49fa-93d8-5046a0f4fe6c"
   },
   "outputs": [],
   "source": [
    "########## Modify this code chunk ##########\n",
    "\n",
    "# Run PCA\n",
    "\n",
    "# Plot PCA\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(, , s=3, label='inactive') \n",
    "ax.scatter(, , color='red', s= 3, label='active')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "httDJiLEfv-V"
   },
   "source": [
    "What is the explained variance ratio of the 100 principal components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drDMqJFufv-V",
    "outputId": "656f90bb-4229-4709-b12c-4d169bdfb7dd"
   },
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjeDno24fv-V"
   },
   "source": [
    "What patterns do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNL6ut_zfv-W"
   },
   "source": [
    "### 1.3 (10 points) t-SNE analysis on Molecular Fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjHBHIzFfv-W"
   },
   "source": [
    "Perform t-SNE on the obtained principal components, with perplexity value of 2, 30, and 500. Plot the results and label your plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "em4B-BO8fv-W",
    "outputId": "71f418c4-6b0e-46ea-f9c8-c287a1f41c7a"
   },
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T93-5HsXfv-W"
   },
   "source": [
    "What differences do you see between the 3 t-SNE plots? What patterns do you observe in the perplexity = 30 plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9M5tSpUfv-X"
   },
   "outputs": [],
   "source": [
    "########## Insert your answer ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fvhqFzlfv-X"
   },
   "source": [
    "### 1.4 Graduate (20 points) Are the low dimensional embeddings meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5BqwtE1fv-Y"
   },
   "source": [
    "Split the data into 10 folds. For each fold, train on the other 9 folds and validate on the last fold. Record your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBHOcCZ9fv-Y"
   },
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ajtwSubfv-Y"
   },
   "source": [
    "Classify your predictions into True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZY_EWdBfv-Z"
   },
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kh9L_0psfv-Z"
   },
   "source": [
    "Plot the 2D t-SNE embeddings (perplexity = 30) colored by the four classification classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "os2w-r07fv-Z",
    "outputId": "e7cfd762-9545-4865-fe69-f5de15e3eba7"
   },
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac7UGJU5fv-b"
   },
   "source": [
    "What pattern do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OynCwoxfv-b"
   },
   "outputs": [],
   "source": [
    "########## Insert your answer ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Variational auto-encoders for SMILES strings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get data \n",
    "wget.download(\"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/nonbio_version/zinc_50k.csv\", \"./\")\n",
    "\n",
    "wget.download(\"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/nonbio_version/zinc_50k.csv\", \"./\")\n",
    "    \n",
    "# Get pretrained model\n",
    "wget.download(\"https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps4/data/nonbio_version/vae-050-0.06.pth\", \"./\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 (5 points) One-hot encode SMILES strings into padded numerical vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Character list \n",
    "moses_charset = ['2', 'o', 'C', 'I', 'O', 'H', 'n', 'N', '=', '+', '#', '-', 'c',\n",
    "                 'B', 'l', '7', 'r', 'S', 's', '4', '6', '[', '5', ']', 'F', '3', \n",
    "                 'P', '(', ')', '1', ' ']\n",
    "\n",
    "# Define encoder \n",
    "enc = preprocessing.LabelEncoder().fit(moses_charset)\n",
    "\n",
    "# Read data \n",
    "df = pd.read_csv(\"./zinc_50k.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encode SMILES strings into padded categorical vectors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########\n",
    "\n",
    "# Find out the longest SMILES string, pad and encode into categorical vectors"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make train/validation/test Datasets and DataLoaders."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test = None\n",
    "X_train, X_val = None\n",
    "\n",
    "train_data = None\n",
    "train_loader = None\n",
    "\n",
    "val_data = None\n",
    "val_loader = None\n",
    "\n",
    "test_data = None\n",
    "test_loader = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 (15 points) Implement the Reparametrization Trick for VAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Molecular VAE model \n",
    "\n",
    "class MolVAE(nn.Module):\n",
    "    def __init__(self,  rnn_enc_hid_dim, enc_nconv,\n",
    "                         encoder_hid, z_dim, \n",
    "                         rnn_dec_hid_dim, dec_nconv, smiles_len, nchar\n",
    "                         ):\n",
    "        '''\n",
    "            SMILES VAE model \n",
    "            \n",
    "                rnn_enc_hid_dim: hidden dimension for the GRU encoder \n",
    "                enc_nconv: number of recurrent layers for the GRU decoder\n",
    "                encoder_hid: dimension of GUR encoder readout\n",
    "                z_dim: number of latent variable \n",
    "                rnn_dec_hid_dim: hidden dimension for the GRU decoder \n",
    "                dec_nconv: number of recurrent layers for the GRU decoder\n",
    "                smiles_len: total length of padded SMILES string \n",
    "                nchar: number of possible characters \n",
    "                \n",
    "        '''\n",
    "        \n",
    "        super(MolVAE, self).__init__()\n",
    "        \n",
    "        self.smiles_len = smiles_len\n",
    "        self.nchar = nchar\n",
    "        # Embedding layer\n",
    "        self.embed = nn.Embedding(self.nchar, rnn_enc_hid_dim)\n",
    "        # Encoding GRU\n",
    "        self.rnn_enc = nn.GRU(rnn_enc_hid_dim, rnn_enc_hid_dim, enc_nconv, batch_first=True)\n",
    "        # MLP to transfrom hidden output from Encoding GRU\n",
    "        self.mlp0 = nn.Linear(rnn_enc_hid_dim, encoder_hid)\n",
    "        # Network to parametrize mu\n",
    "        self.mu_network = nn.Linear(encoder_hid, z_dim)\n",
    "        # Network to parametrize log variance\n",
    "        self.logvar_network = nn.Linear(encoder_hid, z_dim)\n",
    "        # Decoding GRU\n",
    "        self.rnn_dec = nn.GRU(z_dim, rnn_dec_hid_dim, dec_nconv, batch_first=True)\n",
    "        # Output SMILES characters\n",
    "        self.readout = nn.Linear(rnn_dec_hid_dim, self.nchar)\n",
    "\n",
    "    def encode(self, x):\n",
    "        '''Output mean and log variance of the encoded SMILES'''\n",
    "        output, hn = self.rnn_enc(x)\n",
    "        h = torch.nn.functional.relu(self.mlp0(hn[-1]))\n",
    "        return self.mu_network(h), self.logvar_network(h)\n",
    "    \n",
    "    def get_std(self, logvar):\n",
    "        '''Transform log variance to standard deviation'''\n",
    "        ################ Your code #################\n",
    "\n",
    "    def reparametrize(self, mu, std):\n",
    "        '''The reparametrization trick'''\n",
    "        if self.training:\n",
    "            ################ Your code #################\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        '''Decoder to reconstruct latent variable back to SMILES'''\n",
    "        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, self.smiles_len, 1)\n",
    "        out, h = self.rnn_dec(z)\n",
    "        out_reshape = out.contiguous().view(-1, out.size(-1))\n",
    "        \n",
    "        y0 = self.readout(out_reshape)\n",
    "        y = y0.contiguous().view(out.size(0), -1, y0.size(-1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embed(x) # Get SMILES embedding \n",
    "        mu, logvar = self.encode(x_embed) # Encoding SMILES to latent representations \n",
    "        std = self.get_std(logvar) # Transfrom log variance to std.\n",
    "        z = self.reparametrize(mu, std) # Reparametrization trick \n",
    "        smiles_recon = self.decode(z)  # Reconstruct SMILES string \n",
    "        return smiles_recon, mu, std"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test your model by comparing your sampling with N(0, 1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Simply run this chunk ##########\n",
    "\n",
    "# Define your model \n",
    "model = MolVAE(rnn_enc_hid_dim=256, enc_nconv=1, \n",
    "                     encoder_hid=256, z_dim=128, rnn_dec_hid_dim=512,\n",
    "                    dec_nconv=3, nchar=31, smiles_len=max_len)\n",
    "\n",
    "# Compare your sampling with N(0, 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "sample = model.reparametrize(torch.zeros(1000), torch.ones(1000))\n",
    "plt.hist(sample.detach().cpu().numpy(), density=True)\n",
    "\n",
    "# Plot between -10 and 10 with .001 steps.\n",
    "x_axis = np.arange(-7, 7, 0.001)\n",
    "plt.plot(x_axis, norm.pdf(x_axis,0,1)) # Mean = 0, SD = 1.\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 (10 points) Implement the SMILES VAE loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement your loss function here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, std):\n",
    "    ########## Modify this code chunk ##########\n",
    "    BCE = \n",
    "    KLD = \n",
    "    return BCE, KLD"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 (5 points) Train your model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the following cells to train your model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Simply run this chunk ##########\n",
    "def loop(model, loader, epoch, beta=0.05, evaluation=False):\n",
    "    '''\n",
    "        Train/test your VAE model\n",
    "    '''\n",
    "    \n",
    "    if evaluation:\n",
    "        model.eval()\n",
    "        mode = \"eval\"\n",
    "    else:\n",
    "        model.train()\n",
    "        mode = 'train'\n",
    "    batch_losses = []\n",
    "        \n",
    "    tqdm_data = tqdm(loader, position=0, leave=True, desc='{} (epoch #{})'.format(mode, epoch))\n",
    "    for data in tqdm_data:\n",
    "        \n",
    "        x = data[0].to(device)\n",
    "        recon_batch, mu, std = model(x)\n",
    "        loss_recon, loss_kl = loss_function(recon_batch, x, mu, std)\n",
    "        loss = loss_recon + beta * loss_kl     \n",
    "        \n",
    "        if not evaluation:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        postfix = ['recon loss={:.3f}'.format(loss_recon.item()) ,\n",
    "                   'KL loss={:.3f}'.format(loss_kl.item()) ,\n",
    "                   'total loss={:.3f}'.format(loss.item()) , \n",
    "                   'avg. loss={:.3f}'.format(np.array(batch_losses).mean())]\n",
    "        \n",
    "        tqdm_data.set_postfix_str(' '.join(postfix))\n",
    "    \n",
    "    return np.array(batch_losses).mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Simply run this chunk ##########\n",
    "device = 0\n",
    "\n",
    "model = MolVAE(rnn_enc_hid_dim=367, enc_nconv=2, \n",
    "                     encoder_hid=512, z_dim=171, rnn_dec_hid_dim=512,\n",
    "                    dec_nconv=1, nchar=31, smiles_len=max_len)\n",
    "                      \n",
    "model = model.to(device)\n",
    "\n",
    "#load pretrained model \n",
    "model.load_state_dict(torch.load(\"./vae-050-0.06.pth\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Simply run this chunk ##########\n",
    "optimizer = optim.Adam(model.parameters(),lr=5e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optional: mount your Google Drive to save your model and files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Optional: simply run this chunk ##########\n",
    "# Optional: mount your google drive to save model and files\n",
    "# Uncomment below lines if of interest\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#mydrive = '/content/drive/MyDrive'"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Simply run this chunk ##########\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    \n",
    "    # sample_recon(model, epoch, val_loader, enc)\n",
    "    train_loss = loop(model, train_loader, epoch, 0.001)\n",
    "    val_loss = loop(model, val_loader, epoch, 0.001,  evaluation=True)\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # optional: save model \n",
    "#     if epoch % 15 == 0:\n",
    "#         torch.save(model.state_dict(),\n",
    "#                 './{}/vae-{:03d}-{:.2f}.pth'.format(mydrive, epoch, train_loss))\n",
    "        \n",
    "#         torch.save(optimizer.state_dict(),\n",
    "#             './{}/optim-{:03d}-{:.2f}.pth'.format(mydrive, epoch, train_loss))\n",
    "\n",
    "    if epoch == 0:\n",
    "        best_loss = train_loss.item()\n",
    "    else:\n",
    "        if train_loss.item() < best_loss:\n",
    "            best_loss = train_loss.item()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 (20 points) Sample new molecules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some helper functions for you."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def index2smiles(mol_index, enc):\n",
    "    '''Transform your array of character indices back to SMILES'''\n",
    "    smiles_charlist = enc.inverse_transform(np.array(mol_index))\n",
    "    smiles = ''.join(smiles_charlist).strip(\" \")\n",
    "    \n",
    "    return smiles\n",
    "\n",
    "def check_smiles_valid(smiles):\n",
    "    '''Check if SMILES string is valid'''\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        valid = True \n",
    "    else:\n",
    "        valid = False \n",
    "    return valid"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Randomly select two SMILES in your test data, interpolate 10 points between them, and decode those points. Test them for accuracy and draw the scatter plot of the lower 2 dimensions. Then visualize any molecules that worked."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Modify this code chunk ##########\n",
    "\n",
    "# select a starting and ending molecule\n",
    "\n",
    "start = index2smiles(test_loader.dataset.__getitem__(random.choices(range(len(test_loader.dataset)), k=1))[0].numpy().reshape(-1), enc)\n",
    "end = index2smiles(test_loader.dataset.__getitem__(random.choices(range(len(test_loader.dataset)), k=1))[0].numpy().reshape(-1), enc)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "################ Your code #################\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Produce a scatter plot with the first two dimensions of $z$ of your test molecules and newly sampled molecules in the same figure. Color differently the test points and generated points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw different molecules you generated."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "########## Insert your code in this chunk ##########\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why does the VAE sometimes fail to generate valid SMILES strings?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*INSERT YOUR ANSWER HERE*"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pset3_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
